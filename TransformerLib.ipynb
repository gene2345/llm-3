{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f6b0a-8a5a-4b42-a9c9-e4d4dc3031a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leege\\OneDrive\\Documents\\llm-trial\\llm-3\\llm-1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '1', 'compatible_brands': 'isommp41mp42', 'creation_time': '2025-03-22T16:19:30.000000Z'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [720, 1280], 'bitrate': 3032, 'fps': 29.68, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'creation_time': '2025-03-22T16:19:30.000000Z', 'handler_name': 'Core Media Video', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 61, 'metadata': {'Metadata': '', 'creation_time': '2025-03-22T16:19:30.000000Z', 'handler_name': 'Core Media Audio', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 3.1, 'bitrate': 3102, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [720, 1280], 'video_bitrate': 3032, 'video_fps': 29.68, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 61, 'video_duration': 3.1, 'video_n_frames': 92}\n",
      "C:\\Users\\leege\\OneDrive\\Documents\\llm-trial\\llm-3\\llm-1\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i C:\\Users\\leege\\Downloads\\testVideo.MOV -loglevel error -f image2pipe -vf scale=720:1280 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (46669 > 32768). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "C:\\Users\\leege\\OneDrive\\Documents\\llm-trial\\llm-3\\llm-1\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from moviepy import VideoFileClip\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def process_video(video_path, max_frames=64):\n",
    "    video = VideoFileClip(video_path)\n",
    "    frame_rate = video.fps\n",
    "    total_frames = int(video.duration * frame_rate)\n",
    "    frame_indices = np.linspace(0, total_frames - 1, min(max_frames, total_frames), dtype=int)\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        frame = video.get_frame(idx / frame_rate)\n",
    "        frame_pil = Image.fromarray(frame)\n",
    "        frames.append(frame_pil)\n",
    "    return frames\n",
    "\n",
    "# Initialize the processor and model\n",
    "model_id = \"llava-hf/llava-interleave-qwen-0.5b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    load_in_4bit=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Process the video\n",
    "video_path = r\"C:\\Users\\leege\\Downloads\\testVideo.MOV\"  # Use raw string literal for Windows paths\n",
    "frames = process_video(video_path)\n",
    "\n",
    "# Prepare the conversation with image tokens\n",
    "image_tokens = \" \".join([\"<image>\"] * len(frames))\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"What are these?\"}] + [{\"type\": \"image\", \"image\": frame} for frame in frames],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "# Tokenize the prompt\n",
    "inputs = processor(images=frames, text=prompt, return_tensors=\"pt\", padding=True).to(\"cuda\", torch.float16)\n",
    "\n",
    "# Generate response\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "# Decode and print the response\n",
    "response = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
